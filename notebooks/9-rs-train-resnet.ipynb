{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a RESNET model on the esc50 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspaces/GADME\n"
     ]
    }
   ],
   "source": [
    "# change working directory to the root of the project\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from omegaconf import OmegaConf\n",
    "import torchvision\n",
    "import torch\n",
    "import torchmetrics.classification\n",
    "\n",
    "from src.modules.base_module import BaseModule\n",
    "from src.datamodule.esc50_datamodule import ESC50\n",
    "from src.utils.ast_extractor import CustomASTFeatureExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_config = OmegaConf.create({\n",
    "    \"dataset\": {\n",
    "        \"data_dir\": \"/workspaces/GADME/data\",\n",
    "        \"dataset_name\": \"esc50\",\n",
    "        \"hf_path\": \"ashraq/esc50\",\n",
    "        \"hf_name\": None,\n",
    "        \"seed\": 42,\n",
    "        \"feature_extractor\": {\n",
    "            \"_target_\": 'src.utils.ast_extractor.CustomASTFeatureExtractor',\n",
    "            \"n_classes\": 50,\n",
    "            \"n_workers\": 1,\n",
    "            \"column_list\": [\"input_values\", \"target\"],\n",
    "            \"val_split\": 0.2,\n",
    "            \"sampling_rate\": 32000,\n",
    "            \"return_tensor\": 'pt',\n",
    "        },\n",
    "        \"n_classes\": 50,\n",
    "        \"n_workers\": 16,\n",
    "        \"column_list\": [\"input_values\", \"target\"],\n",
    "        \"val_split\": 0.2,\n",
    "    },\n",
    "    \"loaders\": {\n",
    "        \"train\": {\n",
    "            \"batch_size\": 6,\n",
    "            \"shuffle\": True,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": False,\n",
    "            \"pin_memory\": False\n",
    "        },\n",
    "        \"valid\": {\n",
    "            \"batch_size\": 6,\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": False,\n",
    "            \"pin_memory\": False\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"batch_size\": 6,\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": False,\n",
    "            \"pin_memory\": False\n",
    "        },\n",
    "    },\n",
    "    \"transforms\": {\n",
    "        \"use_channel_dim\": False,\n",
    "        \"normalize\": True,\n",
    "        \"use_spectrogram\": True,\n",
    "        \"n_fft\": 1024,\n",
    "        \"hop_length\": 79,\n",
    "        \"n_mels\": 128,\n",
    "        \"db_scale\": True,\n",
    "        \"target_height\": 32,\n",
    "        \"target_width\": 32,\n",
    "        \"waveform_augmentations\": {\n",
    "            \"colored_noise\": {\n",
    "                \"prob\": 0.5,\n",
    "                \"min_snr_in_db\": 3.0,\n",
    "                \"max_snr_in_db\": 30.0,\n",
    "                \"min_f_decay\": -2.0,\n",
    "                \"max_f_decay\": 2.0\n",
    "            },\n",
    "        },\n",
    "        \"spectrogram_augmentations\": {\n",
    "            \"time_masking\": {\n",
    "                \"time_mask_param\": 100,\n",
    "                \"prob\": 0.5\n",
    "            },\n",
    "            \"frequency_masking\": {\n",
    "                \"freq_mask_param\": 100,\n",
    "                \"prob\": 0.5\n",
    "            },\n",
    "            \"time_stretch\": {\n",
    "                \"prob\": 0.5,\n",
    "                \"min_rate\": 0.8,\n",
    "                \"max_rate\": 1.2\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_datamodule = ESC50(dataset=esc50_config.dataset, loaders=esc50_config.loaders, transforms=esc50_config.transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4be581a7204bf08025d6d0ad6c1f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b532789c7be4104b96ba60b2f1fa6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb742616e744ecb8eb25ab2cc6a8f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0639c29128144adaa6e18725790dae5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "esc50_datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_datamodule.setup(stage=\"fit\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = esc50_datamodule.train_dataloader()\n",
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-3.8527, -3.9735, -4.2276,  ..., -5.1062, -5.1062, -5.1062],\n",
       "           [-3.2676, -3.3885, -3.6425,  ..., -4.8009, -4.7123, -4.8226],\n",
       "           [-5.1062, -3.8351, -3.3042,  ..., -3.2593, -3.2996, -3.3942],\n",
       "           ...,\n",
       "           [-3.1246, -3.0223, -2.8535,  ..., -3.6693, -3.8878, -4.1237],\n",
       "           [-3.1658, -3.1461, -3.1157,  ..., -3.9745, -3.9012, -3.8259],\n",
       "           [-3.2888, -3.3467, -3.5316,  ..., -3.9717, -3.9632, -4.0572]]],\n",
       " \n",
       " \n",
       "         [[[-4.1841, -4.1800, -3.9135,  ..., -3.2461, -2.7151, -2.4202],\n",
       "           [-3.5990, -3.5949, -3.3285,  ..., -2.6610, -2.1300, -1.8351],\n",
       "           [-3.7290, -3.5733, -3.2701,  ..., -2.9683, -3.0861, -2.3946],\n",
       "           ...,\n",
       "           [-2.8210, -1.9241, -1.3246,  ..., -1.6116, -1.4023, -1.2282],\n",
       "           [-1.4854, -1.4314, -1.3282,  ..., -1.7946, -1.9609, -2.0002],\n",
       "           [-1.4850, -1.5332, -1.6557,  ..., -1.2432, -1.2595, -1.0633]]],\n",
       " \n",
       " \n",
       "         [[[ 0.5111,  0.4707,  0.3381,  ..., -0.9272, -1.1783, -1.6288],\n",
       "           [ 1.0962,  1.0557,  0.9232,  ..., -0.3421, -0.5932, -1.0438],\n",
       "           [ 0.5527,  0.4719,  0.2226,  ..., -0.5466, -0.7305, -0.8012],\n",
       "           ...,\n",
       "           [ 2.6537,  2.5989,  2.4265,  ...,  0.2048,  0.2193,  0.1848],\n",
       "           [ 2.8445,  2.7820,  2.5910,  ...,  0.6067,  0.5746,  0.4556],\n",
       "           [ 3.2010,  3.1521,  2.9968,  ...,  0.5345,  0.6138,  0.5859]]],\n",
       " \n",
       " \n",
       "         [[[ 0.8222,  1.3291,  1.7004,  ...,  1.5178,  2.0026,  2.2222],\n",
       "           [ 1.4073,  1.9142,  2.2855,  ...,  2.1028,  2.5877,  2.8072],\n",
       "           [ 2.4530,  2.4698,  2.4880,  ...,  2.4311,  2.5231,  2.6351],\n",
       "           ...,\n",
       "           [-0.9360, -0.8155, -0.6668,  ..., -0.1949, -0.1340, -0.1784],\n",
       "           [-0.4521, -0.3438, -0.2238,  ..., -0.3788, -0.3288, -0.2586],\n",
       "           [ 0.7283,  0.7178,  0.6989,  ..., -0.6610, -0.5018, -0.2360]]],\n",
       " \n",
       " \n",
       "         [[[-1.4647, -1.4702, -1.5736,  ..., -1.1588, -1.0635, -0.9503],\n",
       "           [-0.8796, -0.8852, -0.9885,  ..., -0.5738, -0.4784, -0.3652],\n",
       "           [-0.8904, -0.9925, -1.2737,  ...,  0.6976,  0.7566,  0.7761],\n",
       "           ...,\n",
       "           [-1.9148, -1.9680, -2.1154,  ...,  0.4320,  0.3092,  0.0676],\n",
       "           [-2.3311, -2.3885, -2.5768,  ...,  0.9677,  0.9621,  0.8681],\n",
       "           [-2.4121, -2.2928, -2.1331,  ...,  1.3106,  1.3592,  1.2992]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2466,  2.2292,  2.1787,  ...,  3.2816,  3.4477,  3.5154],\n",
       "           [ 2.8317,  2.8143,  2.7638,  ...,  3.8667,  4.0327,  4.1005],\n",
       "           [ 2.5814,  2.5194,  2.3259,  ...,  3.3673,  3.3614,  3.3542],\n",
       "           ...,\n",
       "           [ 2.8126,  2.7504,  2.5678,  ...,  2.7891,  2.7155,  2.5415],\n",
       "           [ 2.8674,  2.8029,  2.6096,  ...,  2.9176,  2.7856,  2.5285],\n",
       "           [ 2.8350,  2.8101,  2.7491,  ...,  2.9881,  2.9250,  2.8017]]]]),\n",
       " tensor([29, 32,  6, 41, 15, 42]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 32, 32])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdbc0ec88b0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the first spectrogram\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(batch[0][2].squeeze().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_config = OmegaConf.create({\n",
    "    \"network\": {\n",
    "        \"model_name\": \"resnet50\",\n",
    "        \"model\": {\n",
    "            \"_target_\": 'torchvision.models.resnet50',\n",
    "            \"weights\": 'ResNet50_Weights.IMAGENET1K_V1'\n",
    "        },\n",
    "        \"torch_compile\": False\n",
    "    },\n",
    "    \"output_activation\": {\n",
    "        \"_target_\": 'torch.softmax',\n",
    "        \"dim\": 1\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"_target_\": 'torch.nn.CrossEntropyLoss'\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"_target_\": 'torch.optim.Adam',\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.01\n",
    "    },\n",
    "    \"lr_scheduler\": {\n",
    "        \"_target_\": 'torch.optim.lr_scheduler',\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"main\": {\n",
    "            \"_target_\": 'torchmetrics.classification.Accuracy',\n",
    "            \"task\": \"multiclass\",\n",
    "            \"num_classes\": 50,\n",
    "            \"top_k\": 1,\n",
    "        },\n",
    "        \"val_best\": {   \n",
    "            \"_target_\": 'torchmetrics.MaxMetric',\n",
    "        }\n",
    "    },\n",
    "    \"num_epochs\": 10,\n",
    "    \"logging_params\": None,\n",
    "    \"len_trainset\": 50000\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetModule = BaseModule(\n",
    "    network=module_config.network,\n",
    "    output_activation= module_config.output_activation,\n",
    "    loss=module_config.loss,\n",
    "    optimizer=module_config.optimizer,\n",
    "    lr_scheduler=module_config.lr_scheduler,\n",
    "    metrics=module_config.metrics,\n",
    "    logging_params=module_config.logging_params,\n",
    "    num_epochs=module_config.num_epochs,\n",
    "    len_trainset=module_config.len_trainset\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModule(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       "  (train_metric): MulticlassAccuracy()\n",
       "  (train_add_metrics): MetricCollection,\n",
       "    postfix=/train\n",
       "  )\n",
       "  (valid_metric): MulticlassAccuracy()\n",
       "  (valid_metric_best): MaxMetric()\n",
       "  (valid_add_metrics): MetricCollection,\n",
       "    postfix=/valid\n",
       "  )\n",
       "  (test_metric): MulticlassAccuracy()\n",
       "  (test_add_metrics): MetricCollection,\n",
       "    postfix=/test\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnetModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.models.benchmark_models import LightningResNet, ResNetVersion\n",
    "resnetModule = LightningResNet(\n",
    "    baseline_architecture='resnet18',\n",
    "    num_classes=50,\n",
    "    num_channels=1,\n",
    "    learning_rate=0.001,\n",
    "    pretrained=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningResNet(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (acc): MulticlassAccuracy()\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=50, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnetModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss   | 0     \n",
      "1 | acc       | MulticlassAccuracy | 0     \n",
      "2 | model     | ResNet             | 11.2 M\n",
      "-------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.777    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25dc3468a8643468c474ff8e4e93f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 32 elements not 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/GADME/notebooks/9-rs-train-resnet.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f64617461312f7273636877696e6765722f6769742f4741444d45222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f64617461312f7273636877696e6765722f6769742f4741444d452f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2Bkiel.ins.informatik.uni-kiel.de/workspaces/GADME/notebooks/9-rs-train-resnet.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f64617461312f7273636877696e6765722f6769742f4741444d45222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f64617461312f7273636877696e6765722f6769742f4741444d452f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2Bkiel.ins.informatik.uni-kiel.de/workspaces/GADME/notebooks/9-rs-train-resnet.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f64617461312f7273636877696e6765722f6769742f4741444d45222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f64617461312f7273636877696e6765722f6769742f4741444d452f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2Bkiel.ins.informatik.uni-kiel.de/workspaces/GADME/notebooks/9-rs-train-resnet.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(resnetModule, esc50_datamodule)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    991\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m   1032\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1033\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1034\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1035\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1064\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mis_last_batch \u001b[39m=\u001b[39m data_fetcher\u001b[39m.\u001b[39mdone\n\u001b[1;32m    133\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    385\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m step_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    389\u001b[0m     \u001b[39melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_args)\n\u001b[1;32m    393\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    396\u001b[0m     \u001b[39m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module:\n\u001b[1;32m    402\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_redirection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspaces/GADME/src/modules/models/benchmark_models.py:151\u001b[0m, in \u001b[0;36mLightningResNet.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Defines a single validation step.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m    batch (Tuple[torch.Tensor, torch.Tensor]): A tuple containing input data and corresponding labels.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    batch_idx (int): The index of the current batch.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m x, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m--> 151\u001b[0m preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x)\n\u001b[1;32m    153\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(preds, y)\n\u001b[1;32m    154\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39macc(preds, y)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspaces/GADME/src/modules/models/benchmark_models.py:100\u001b[0m, in \u001b[0;36mLightningResNet.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     92\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Defines the forward pass, i.e., the computation performed on each call.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m        torch.Tensor: The output tensor produced by the ResNet model.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/torchvision/models/resnet.py:269\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m--> 269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2452\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 32 elements not 64"
     ]
    }
   ],
   "source": [
    "from lightning import Trainer\n",
    "trainer = Trainer(max_epochs=10, devices=1)\n",
    "trainer.fit(resnetModule, esc50_datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gadme-zu58s5te-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
