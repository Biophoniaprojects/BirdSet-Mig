{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a RESNET model on the esc50 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspaces/GADME\n"
     ]
    }
   ],
   "source": [
    "# change working directory to the root of the project\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from omegaconf import OmegaConf\n",
    "import torchvision\n",
    "import torch\n",
    "import torchmetrics.classification\n",
    "\n",
    "from src.modules.base_module import BaseModule\n",
    "from src.datamodule.esc50_datamodule import ESC50\n",
    "from src.utils.ast_extractor import CustomASTFeatureExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_config = OmegaConf.create({\n",
    "    \"dataset\": {\n",
    "        \"data_dir\": \"/workspaces/GADME/data\",\n",
    "        \"dataset_name\": \"esc50\",\n",
    "        \"hf_path\": \"ashraq/esc50\",\n",
    "        \"hf_name\": None,\n",
    "        \"seed\": 42,\n",
    "        \"feature_extractor\": {\n",
    "            \"_target_\": 'src.utils.ast_extractor.CustomASTFeatureExtractor',\n",
    "            \"n_classes\": 50,\n",
    "            \"n_workers\": 1,\n",
    "            \"column_list\": [\"input_values\", \"target\"],\n",
    "            \"val_split\": 0.2,\n",
    "            \"sampling_rate\": 32000,\n",
    "        },\n",
    "        \"n_classes\": 50,\n",
    "        \"n_workers\": 16,\n",
    "        \"column_list\": [\"input_values\", \"target\"],\n",
    "        \"val_split\": 0.2,\n",
    "    },\n",
    "    \"loaders\": {\n",
    "        \"train\": {\n",
    "            \"batch_size\": 6,\n",
    "            \"shuffle\": True,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": False,\n",
    "            \"pin_memory\": False\n",
    "        },\n",
    "        \"valid\": {\n",
    "            \"batch_size\": 6,\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": False,\n",
    "            \"pin_memory\": False\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"batch_size\": 6,\n",
    "            \"shuffle\": False,\n",
    "            \"num_workers\": 4,\n",
    "            \"drop_last\": False,\n",
    "            \"pin_memory\": False\n",
    "        },\n",
    "    },\n",
    "    \"transforms\": {\n",
    "        \"use_channel_dim\": False,\n",
    "        \"normalize\": True,\n",
    "        \"use_spectrogram\": True,\n",
    "        \"n_fft\": 1024,\n",
    "        \"hop_length\": 79,\n",
    "        \"n_mels\": 128,\n",
    "        \"db_scale\": True,\n",
    "        \"target_height\": 32,\n",
    "        \"target_width\": 32,\n",
    "        \"waveform_augmentations\": {\n",
    "            \"colored_noise\": {\n",
    "                \"prob\": 0.5,\n",
    "                \"min_snr_in_db\": 3.0,\n",
    "                \"max_snr_in_db\": 30.0,\n",
    "                \"min_f_decay\": -2.0,\n",
    "                \"max_f_decay\": 2.0\n",
    "            },\n",
    "        },\n",
    "        \"spectrogram_augmentations\": {\n",
    "            \"time_masking\": {\n",
    "                \"time_mask_param\": 100,\n",
    "                \"prob\": 0.5\n",
    "            },\n",
    "            \"frequency_masking\": {\n",
    "                \"freq_mask_param\": 100,\n",
    "                \"prob\": 0.5\n",
    "            },\n",
    "            \"time_stretch\": {\n",
    "                \"prob\": 0.5,\n",
    "                \"min_rate\": 0.8,\n",
    "                \"max_rate\": 1.2\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_datamodule = ESC50(dataset=esc50_config.dataset, loaders=esc50_config.loaders, transforms=esc50_config.transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e142f96a4d784c2aa63d8fad266b60d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dace0f627442e282abcb43240b60cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e642eecd4a495db9d2b892d51c3d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0c8356affe4a279b9f894c4c63e7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "esc50_datamodule.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_datamodule.setup(stage=\"fit\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = esc50_datamodule.train_dataloader()\n",
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 32, 32])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f97acb771c0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the first spectrogram\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(batch['input_values'][3].squeeze().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_config = OmegaConf.create({\n",
    "    \"network\": {\n",
    "        \"model_name\": \"resnet50\",\n",
    "        \"model\": {\n",
    "            \"_target_\": 'torchvision.models.resnet50',\n",
    "            \"weights\": 'ResNet50_Weights.IMAGENET1K_V1'\n",
    "        },\n",
    "        \"torch_compile\": False\n",
    "    },\n",
    "    \"output_activation\": {\n",
    "        \"_target_\": 'torch.softmax',\n",
    "        \"dim\": 1\n",
    "    },\n",
    "    \"loss\": {\n",
    "        \"_target_\": 'torch.nn.CrossEntropyLoss'\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"_target_\": 'torch.optim.Adam',\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.01\n",
    "    },\n",
    "    \"lr_scheduler\": {\n",
    "        \"_target_\": 'torch.optim.lr_scheduler',\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"main\": {\n",
    "            \"_target_\": 'torchmetrics.classification.Accuracy',\n",
    "            \"task\": \"multiclass\",\n",
    "            \"num_classes\": 50,\n",
    "            \"top_k\": 1,\n",
    "        },\n",
    "        \"val_best\": {   \n",
    "            \"_target_\": 'torchmetrics.MaxMetric',\n",
    "        }\n",
    "    },\n",
    "    \"num_epochs\": 10,\n",
    "    \"logging_params\": None,\n",
    "    \"len_trainset\": 50000\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetModule = BaseModule(\n",
    "    network=module_config.network,\n",
    "    output_activation= module_config.output_activation,\n",
    "    loss=module_config.loss,\n",
    "    optimizer=module_config.optimizer,\n",
    "    lr_scheduler=module_config.lr_scheduler,\n",
    "    metrics=module_config.metrics,\n",
    "    logging_params=module_config.logging_params,\n",
    "    num_epochs=module_config.num_epochs,\n",
    "    len_trainset=module_config.len_trainset\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModule(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       "  (train_metric): MulticlassAccuracy()\n",
       "  (train_add_metrics): MetricCollection,\n",
       "    postfix=/train\n",
       "  )\n",
       "  (valid_metric): MulticlassAccuracy()\n",
       "  (valid_metric_best): MaxMetric()\n",
       "  (valid_add_metrics): MetricCollection,\n",
       "    postfix=/valid\n",
       "  )\n",
       "  (test_metric): MulticlassAccuracy()\n",
       "  (test_add_metrics): MetricCollection,\n",
       "    postfix=/test\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnetModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /workspaces/GADME/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name              | Type               | Params\n",
      "---------------------------------------------------------\n",
      "0 | model             | ResNet             | 25.6 M\n",
      "1 | loss              | CrossEntropyLoss   | 0     \n",
      "2 | train_metric      | MulticlassAccuracy | 0     \n",
      "3 | train_add_metrics | MetricCollection   | 0     \n",
      "4 | valid_metric      | MulticlassAccuracy | 0     \n",
      "5 | valid_metric_best | MaxMetric          | 0     \n",
      "6 | valid_add_metrics | MetricCollection   | 0     \n",
      "7 | test_metric       | MulticlassAccuracy | 0     \n",
      "8 | test_add_metrics  | MetricCollection   | 0     \n",
      "---------------------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.228   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51f7fb1b419459ea9d70f9ab9a2e465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "ResNet.forward() got an unexpected keyword argument 'input_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/GADME/notebooks/9-rs-train-resnet.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f64617461312f7273636877696e6765722f6769742f4741444d45222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f64617461312f7273636877696e6765722f6769742f4741444d452f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2Bkiel.ins.informatik.uni-kiel.de/workspaces/GADME/notebooks/9-rs-train-resnet.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f64617461312f7273636877696e6765722f6769742f4741444d45222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f64617461312f7273636877696e6765722f6769742f4741444d452f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2Bkiel.ins.informatik.uni-kiel.de/workspaces/GADME/notebooks/9-rs-train-resnet.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f64617461312f7273636877696e6765722f6769742f4741444d45222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f64617461312f7273636877696e6765722f6769742f4741444d452f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2Bkiel.ins.informatik.uni-kiel.de/workspaces/GADME/notebooks/9-rs-train-resnet.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(resnetModule, esc50_datamodule)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    991\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m   1032\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1033\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1034\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1035\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1064\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mis_last_batch \u001b[39m=\u001b[39m data_fetcher\u001b[39m.\u001b[39mdone\n\u001b[1;32m    133\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    385\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m step_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    389\u001b[0m     \u001b[39melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_args)\n\u001b[1;32m    393\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    396\u001b[0m     \u001b[39m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-zu58s5te-py3.10/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module:\n\u001b[1;32m    402\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_redirection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspaces/GADME/src/modules/base_module.py:145\u001b[0m, in \u001b[0;36mBaseModule.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m--> 145\u001b[0m     val_loss, preds, targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_step(batch, batch_idx)\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m         val_loss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_metric(preds, targets)\n",
      "File \u001b[0;32m/workspaces/GADME/src/modules/base_module.py:113\u001b[0m, in \u001b[0;36mBaseModule.model_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m--> 113\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbatch)\n\u001b[1;32m    114\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(logits, batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    115\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_activation(logits)\n",
      "File \u001b[0;32m/workspaces/GADME/src/modules/base_module.py:75\u001b[0m, in \u001b[0;36mBaseModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: ResNet.forward() got an unexpected keyword argument 'input_values'"
     ]
    }
   ],
   "source": [
    "from lightning import Trainer\n",
    "trainer = Trainer(max_epochs=10, devices=1)\n",
    "trainer.fit(resnetModule, esc50_datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gadme-zu58s5te-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
