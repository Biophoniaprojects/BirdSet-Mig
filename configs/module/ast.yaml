_target_: src.modules.base_module.BaseModule

model:
  _target_: src.modules.models.ast.ASTSequenceClassifier
  checkpoint: MIT/ast-finetuned-audioset-10-10-0.4593
  num_classes: ${datamodule.dataset.n_classes}

loss:
  _target_: torch.nn.CrossEntropyLoss

optimizer:
  _target_: torch.optim.AdamW
  lr: 5e-5
  weight_decay: 0.01

lr_scheduler:
  scheduler:
    _target_: transformers.get_linear_schedule_with_warmup
  extras:
    interval: step
    warmup_ratio: 0.05
    
metrics: 
  main: 
    _target_: "torchmetrics.classification.Accuracy"
    task: "multiclass"
    num_classes: ${datamodule.dataset.n_classes}
    top_k: 1
  val_best: 
    _target_: "torchmetrics.MaxMetric"
  # additional: 
  #   f1:
  #     _target_: "torchmetrics.classification.MulticlassF1Score"
  #     num_classes: ${datamodule.dataset.n_classes}  
  #   recall:
  #     _target_: "torchmetrics.classification.Recall"
  #     task: "multiclass"
  #     average: "macro"
  #     num_classes: ${datamodule.dataset.n_classes} 

output_activation: 
  _target_: "torch.softmax"
  dim: 1

logging_params:
  on_step: True
  on_epoch: True
  sync_dist: False
  prog_bar: True

model_name: ast
torch_compile: false
# train_metrics:
#   train_accuracy:
#     _target_: "torchmetrics.classification.Accuracy"
#     task: "multiclass" # depends on dataset
#     num_classes: ${datamodule.dataset.n_classes}
#   train_f1:
#     _target_: "torchmetrics.classification.MulticlassF1Score"
#     num_classes: ${datamodule.dataset.n_classes}

# eval_metrics:
#   eval_accuracy:
#     _target_: "torchmetrics.classification.Accuracy"
#     task: "multiclass" # depends on dataset
#     num_classes: ${datamodule.dataset.n_classes}
#   eval_f1:
#     _target_: "torchmetrics.classification.MulticlassF1Score"
#     num_classes: ${datamodule.dataset.n_classes}














