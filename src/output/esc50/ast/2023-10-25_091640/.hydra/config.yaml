val_split: 0.2
seed: 12345
train_batch_size: 5
eval_batch_size: 16
print_freq_eval: 25
print_freq_train: 25
check_freq_model: 15
dataset:
  _target_: src.dataset.esc50_datamodule.ESC50
  data_dir: ${paths.dataset_path}
  dataset_name: esc50
  feature_extractor_name: ${model.model.checkpoint}
  hf_path: ashraq/esc50
  hf_name: None
  seed: ${seed}
  train_batch_size: ${train_batch_size}
  eval_batch_size: ${eval_batch_size}
  val_split: ${val_split}
  column_list:
  - input_values
  - target
  n_classes: 50
  num_workers: 1
model:
  _target_: src.modules.base_module.BaseModule
  model:
    _target_: src.modules.models.ast.ASTSequenceClassifier
    checkpoint: MIT/ast-finetuned-audioset-10-10-0.4593
    num_classes: ${dataset.n_classes}
  loss:
    _target_: torch.nn.CrossEntropyLoss
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 5.0e-05
    weight_decay: 0.01
  lr_scheduler:
    main:
      _target_: transformers.get_linear_schedule_with_warmup
      _partial_: true
    extras:
      warmup_ratio: 0.05
  train_metrics:
    train_accuracy:
      _target_: torchmetrics.classification.Accuracy
      task: multiclass
      num_classes: ${dataset.n_classes}
    train_f1:
      _target_: torchmetrics.classification.MulticlassF1Score
      num_classes: ${dataset.n_classes}
  eval_metrics:
    eval_accuracy:
      _target_: torchmetrics.classification.Accuracy
      task: multiclass
      num_classes: ${dataset.n_classes}
    eval_f1:
      _target_: torchmetrics.classification.MulticlassF1Score
      num_classes: ${dataset.n_classes}
  scheduler_interval: step
  model_name: ast
  torch_compile: false
callbacks:
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val_loss
    patience: 5
    min_delta: 0
  lr_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: step
  time_tracking:
    _target_: src.callbacks.TimeCallback
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  work_dir: ${hydra:runtime.cwd}
  output_dir: ${hydra:runtime.output_dir}
  dataset_path: ${paths.root_dir}/data_gadme
  log_dir: ${paths.output_dir}/logs/
trainer:
  _target_: lightning.Trainer
  default_root_dir: paths.output_dir
  min_epochs: 10
  max_epochs: 10
  accelerator: gpu
  enable_checkpointing: false
  fast_dev_run: false
  devices: 1
  strategy: auto
  gradient_clip_val: 0.5
loggers:
  wandb:
    _target_: pytorch_lightning.loggers.WandbLogger
    _partial_: true
    name: ${model.model_name}_${dataset}_#${seed}
    save_dir: ${paths.log_dir}
    mode: offline
    id: null
    project: gadme
    log_model: false
    entity: deepbirddetect
    tags: []
    job_type: ''
transformations: {}
tags:
- ast
- esc50
data:
  train_batch_size: 64
  eval_batch_size: 64
  num_workers: 1
